{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avant Data Challange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data file to obtain some statistic about the features and target\n",
      "shape of data file:  (80000, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"Read data file to obtain some statistic about the features and target\")\n",
    "data = pd.read_csv('data.csv')\n",
    "print \"shape of data file: \", data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data file:  (80000, 23)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop([\"last_credit_pull_d\", \"last_fico_range_high\", \"last_fico_range_low\"], axis=1)\n",
    "print \"shape of data file: \", data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data file:  (80000, 22)\n"
     ]
    }
   ],
   "source": [
    "# missing values\n",
    "data = data.drop([\"mths_since_last_record\"], axis=1)\n",
    "data[\"inq_last_12m\"] = data[\"inq_last_12m\"].fillna(np.median(data[\"inq_last_12m\"].dropna()))\n",
    "data[\"mths_since_last_delinq\"] = data[\"mths_since_last_delinq\"].fillna(np.median(data[\"mths_since_last_delinq\"].dropna()))\n",
    "print \"shape of data file: \", data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of categorical fetures: \n",
      "['term', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'purpose', 'addr_state', 'earliest_cr_line']\n",
      "List of numerical fetures: \n",
      "['id', 'loan_amnt', 'installment', 'annual_inc', 'dti', 'fico_range_low', 'fico_range_high', 'acc_now_delinq', 'delinq_amnt', 'delinq_2yrs', 'mths_since_last_delinq', 'inq_last_6mths', 'inq_last_12m']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = []\n",
    "categorical_features = []\n",
    "for col, dtype in zip(data.columns, data.dtypes):\n",
    "    if dtype == \"object\":\n",
    "        categorical_features.append(col)\n",
    "    else:\n",
    "        numerical_features.append(col)\n",
    "\n",
    "print \"List of categorical fetures: \"\n",
    "print categorical_features\n",
    "print \"List of numerical fetures: \"\n",
    "print numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue_d\n",
      "earliest_cr_line\n"
     ]
    }
   ],
   "source": [
    "# There are three fetures for date that should be splited into month and year\n",
    "date_features = [\"issue_d\", \"earliest_cr_line\"]\n",
    "\n",
    "# I define a dictionary to convert month to integer variable\n",
    "months = {\"Jan\" : 1, \"Feb\" : 2, \"Mar\" : 3, \"Apr\" : 4, \"May\" : 5, \"Jun\": 6, \"Jul\" : 7, \"Aug\" : 8, \"Sep\" : 9,\n",
    "          \"Oct\" : 10, \"Nov\" : 11, \"Dec\" :12}\n",
    "\n",
    "for col in date_features:\n",
    "    print col\n",
    "    name = col + \"_month\"\n",
    "    data[name] = map(lambda x: months[x.split(\"-\")[0]], data[col])\n",
    "    name = col + \"_year\"\n",
    "    data[name] = map(lambda x: np.int(x.split(\"-\")[1]), data[col])\n",
    "    \n",
    "# Drop the original features\n",
    "data = data.drop(date_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of the objects in emp_length:\n",
      "['10+ years', '2 years', '3 years', '< 1 year', '1 year', 'n/a', '5 years', '4 years', '8 years', '6 years', '9 years', '7 years']\n"
     ]
    }
   ],
   "source": [
    "# clean emp_length\n",
    "print \"list of the objects in emp_length:\"\n",
    "print list(data[\"emp_length\"].value_counts().index)\n",
    "\n",
    "# built a dictionary \n",
    "emp_dict = {'10+ years' : 10, '2 years' : 2, '3 years' : 3, '< 1 year' : 0, '1 year' : 1, 'n/a' : -1, \n",
    "            '5 years' : 5, '4 years' : 4, '8 years' : 8, '6 years' : 6, '9 years' : 9, '7 years' : 7}\n",
    "\n",
    "# I replace missing value with -1\n",
    "data[\"emp_length\"] = map(lambda x: emp_dict[x], data[\"emp_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "object_type = ['term', 'home_ownership', 'verification_status', 'purpose', 'addr_state']\n",
    "data_dummies = pd.get_dummies(data[object_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert object features to int\n"
     ]
    }
   ],
   "source": [
    "# convert object features to int\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "object_type = ['term', 'home_ownership', 'verification_status', 'purpose', 'addr_state']\n",
    "print(\"convert object features to int\")\n",
    "for c in object_type:\n",
    "    data[c] = data[c].fillna(-2)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(data[c].values))\n",
    "    data[c] = lbl.transform(list(data[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Current borrowers who paied more than 50% of entire loan  18033\n"
     ]
    }
   ],
   "source": [
    "#Create target variable\n",
    "data[\"pay_months\"] = data[\"issue_d_year\"] - 2015\n",
    "data[\"pay_months\"] = (13-data[\"issue_d_month\"]) + 12 * data[\"pay_months\"]\n",
    "\n",
    "threshold = 0.5 \n",
    "index_36 = (data.term == 0) & (data.pay_months >= 36*threshold) & (data.loan_status == \"Current\")\n",
    "index_60 = (data.term == 1) & (data.pay_months >= 60*threshold) & (data.loan_status == \"Current\")\n",
    "\n",
    "index = index_36 | index_60\n",
    "print \"Number of Current borrowers who paied more than 50% of entire loan \", sum(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Fully Paid borrowers who paied entire loan  11534\n",
      "Number of Default borrowers  6037\n"
     ]
    }
   ],
   "source": [
    "index_paied = data.loan_status == \"Fully Paid\"\n",
    "index_default = data.loan_status == \"Default\"\n",
    "index_paied_default = index_paied | index_default\n",
    "print \"Number of Fully Paid borrowers who paied entire loan \", sum(index_paied)\n",
    "print \"Number of Default borrowers \", sum(index_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data that can be used for training  35604\n"
     ]
    }
   ],
   "source": [
    "index = index | index_paied_default\n",
    "print \"Number of data that can be used for training \", sum(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a train data set\n",
    "train = data[index]\n",
    "\n",
    "train.loc[:,\"target\"] = 0\n",
    "train.loc[:, \"target\"] = (train.loan_status == \"Default\") * 1\n",
    "train = train.drop(\"loan_status\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce highly correlated feaetures\n",
    "train[\"fico_range\"] = (train[\"fico_range_high\"] + train[\"fico_range_low\"]) / 2.0\n",
    "train = train.drop([\"fico_range_high\", \"fico_range_low\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"clean_data_tree.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 92)\n"
     ]
    }
   ],
   "source": [
    "# make a data set for logistic regression\n",
    "train_lr = pd.concat([data, data_dummies], axis=1)\n",
    "train_lr = train_lr.drop(object_type, axis=1)\n",
    "print train_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lr = train_lr[index]\n",
    "\n",
    "train_lr.loc[:,\"target\"] = 0\n",
    "train_lr.loc[:, \"target\"] = (train_lr.loan_status == \"Default\") * 1\n",
    "train_lr = train_lr.drop(\"loan_status\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce highly correlated feaetures\n",
    "train_lr[\"fico_range\"] = (train_lr[\"fico_range_high\"] + train_lr[\"fico_range_low\"]) / 2.0\n",
    "train_lr = train_lr.drop([\"fico_range_high\", \"fico_range_low\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lr.to_csv(\"clean_data_LR.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
