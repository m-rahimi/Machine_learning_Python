{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data file to obtain some statistic about the features and target\n",
      "shape of data file:  (35604, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Read data file to obtain some statistic about the features and target\")\n",
    "data = pd.read_csv('clean_data_tree.csv')\n",
    "print \"shape of data file: \", data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amin\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class XGBoostClass():\n",
    "    def __init__(self, num_boost_round=10, **kwargs):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = kwargs\n",
    "        self.params.update({'objective': 'multi:softprob'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    " \n",
    "    def predict(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict(X)\n",
    "        return r2_score(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBoostClass(num_class = 2, nround = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data.drop(\"target\", axis=1)\n",
    "target = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.355203122749\n",
      "0.347069938553\n",
      "0.354741107222\n",
      "0.368206980763\n",
      "0.355506957848\n",
      "0.367859146151\n",
      "0.347352054139\n",
      "0.351875386968\n",
      "0.342725291124\n",
      "0.351145876602\n",
      "mean logloss score in 10 folds:  0.354168586212 0.00793660938007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(n_splits = 10, shuffle = True, random_state = 44)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(train):\n",
    "        x0, x1 = train.iloc[train_index], train.iloc[test_index]\n",
    "        y0, y1 = target.iloc[train_index], target.iloc[test_index] \n",
    "        model.fit(x0, y0)            \n",
    "        predict = model.predict(x1)\n",
    "        scores.append(log_loss(y1, predict))\n",
    "        print log_loss(y1, predict)\n",
    "        \n",
    "print \"mean logloss score in 10 folds: \", np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
