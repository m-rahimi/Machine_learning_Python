{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncpu = 8 # It should be modified if run of midawy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: ../Data/store1.h5\n",
      "/miss             frame        (shape->[11437,3])    \n",
      "/prop             frame        (shape->[2883630,254])\n",
      "/train            frame        (shape->[90275,256])  \n"
     ]
    }
   ],
   "source": [
    "store = pd.HDFStore('../Data/store1.h5')\n",
    "print store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = store[\"train\"]\n",
    "prop = store[\"prop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop shape (2883630, 236)\n",
      "train shape (90275, 238)\n"
     ]
    }
   ],
   "source": [
    "dd = ['type_architectural',\n",
    " 'area_basement',\n",
    " 'num_bathroom',\n",
    " 'num_bedroom',\n",
    " 'type_framing',\n",
    " 'num_bathroom_calc',\n",
    " 'type_deck',\n",
    " 'area_liveperi_finished',\n",
    " 'num_bath',\n",
    " 'pooltypeid10',\n",
    " 'region_county',\n",
    " 'type_story',\n",
    " 'type_material',\n",
    " 'area_shed',\n",
    " 'tax_year',\n",
    " 'num_rot75_X',\n",
    " 'num_rot75_Y']\n",
    "\n",
    "train = train.drop(dd + [\"area_total_calc\"], axis=1)\n",
    "prop = prop.drop(dd + [\"area_total_calc\"], axis=1)\n",
    "\n",
    "print \"prop shape \" + str(prop.shape)\n",
    "print \"train shape \" + str(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "0.264 -0.252\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "interval = q3 - q1\n",
    "fac = 8.0\n",
    "interval = interval * fac / 2.\n",
    "hi = interval + mid\n",
    "lo = -interval + mid\n",
    "print hi, lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the x1 data frame:  (81733, 238)\n",
      "Size of the x0 data frame:  (8542, 238)\n",
      "2088 1432\n",
      "Size of the x1 data frame:  (78213, 238)\n",
      "Size of the x0 data frame:  (8542, 238)\n"
     ]
    }
   ],
   "source": [
    "# split the data to 9 months for train and 3 months for test\n",
    "x1 = train[train.month < 10]    # use for train\n",
    "x0 = train[train.month > 9]     # use for test\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape\n",
    "\n",
    "y1 = x1['logerror'].values\n",
    "y0 = x0['logerror'].values\n",
    "\n",
    "index_hi = y1 > hi   # drop 1480 points\n",
    "index_lo = y1 < lo    # drop 947 points\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "y1 = y1[(~index_lo) & (~index_hi)]\n",
    "x1 = x1[(~index_lo) & (~index_hi)]\n",
    "\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.065887853208\n"
     ]
    }
   ],
   "source": [
    "col = [\"rate\", \"depth\", \"nround\", \"subsample\", \"colsample\", \"child\", \"L2\", \"score\"]\n",
    "result = pd.DataFrame(columns=col)\n",
    "\n",
    "for rate in [0.01]:\n",
    "    for depth in [9]:\n",
    "        for nround in [10]:\n",
    "            for sample in [1.0]:\n",
    "                for colsample in [0.5]:\n",
    "                    for child in [1]:\n",
    "                        for L2 in [3]:\n",
    "                            model = CatBoostRegressor(loss_function='MAE', eval_metric='MAE',\n",
    "                                                            iterations=nround, \n",
    "                                                            learning_rate=rate,\n",
    "                                                            depth=depth,\n",
    "                                                            bagging_temperature=sample,\n",
    "                                                            rsm=colsample,\n",
    "                                                            l2_leaf_reg=L2, \n",
    "                                                            thread_count = ncpu,\n",
    "                                                            random_seed=123)\n",
    "\n",
    "                            model.fit(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1), y1)\n",
    "\n",
    "                            score = mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))\n",
    "                            \n",
    "                            print score\n",
    "                            \n",
    "                            result = result.append(pd.DataFrame([[rate, depth, nround, sample, colsample,\n",
    "                                                                      child, L2, score]], columns=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rate  depth  nround  subsample  colsample  child   L2     score\n",
      "0  0.01    9.0    10.0        1.0        0.5    1.0  3.0  0.065888\n"
     ]
    }
   ],
   "source": [
    "result = result.sort_values(\"score\")\n",
    "result.to_csv(\"result.csv\")\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(loss_function='MAE', eval_metric='MAE',\n",
    "        calc_feature_importance=True,\n",
    "        iterations=np.int(result.iloc[0].nround),\n",
    "        learning_rate=result.iloc[0].rate,\n",
    "        depth=np.int(result.iloc[0].depth), \n",
    "        bagging_temperature=result.iloc[0].subsample,\n",
    "        rsm=result.iloc[0].colsample,\n",
    "        l2_leaf_reg=np.int(result.iloc[0].L2),\n",
    "        thread_count = ncpu,\n",
    "        random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data  0.0463481486513\n",
      "Error on 3 months test  0.065887853208\n"
     ]
    }
   ],
   "source": [
    "model.fit(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1), y1) # Train the model without outliers\n",
    "\n",
    "print \"Error on training data \", mean_absolute_error(y1, model.predict(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))\n",
    "print \"Error on 3 months test \", mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance = {}\n",
    "for col, val in zip(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1).columns, model.feature_importance):\n",
    "    importance[col] = val\n",
    "\n",
    "import operator\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "df.to_csv(\"importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data frame:  (90150, 238)\n",
      "Size of the prop data frame:  (2883630, 236)\n"
     ]
    }
   ],
   "source": [
    "# we have duplicate in train :(\n",
    "# we can have three simple strategies\n",
    "# 1- keep first one; 2- keep last one; 3- average\n",
    "# I think the logerror reduce from first to last but I am not sure\n",
    "# it is a very important point\n",
    "duplicate = train[\"id_parcel\"].duplicated(keep='first')\n",
    "train = train[~duplicate]\n",
    "print \"Size of the train data frame: \", train.shape\n",
    "print \"Size of the prop data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "-0.252 0.264\n",
      "-2.09025 2.10225\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "\n",
    "fac = 8.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_train = interval + mid\n",
    "lo_train = -interval + mid\n",
    "\n",
    "fac = 65.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_test = interval + mid\n",
    "lo_test = -interval + mid\n",
    "\n",
    "print lo_train, hi_train\n",
    "print lo_test, hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data frame:  (90150, 236)\n",
      "Size of the prop  data frame:  (2883630, 236)\n",
      "Generate a list of outliers should be droped for training\n",
      "2310 1568\n",
      "Generate a list of outliers should be droped for testing\n",
      "51 46\n"
     ]
    }
   ],
   "source": [
    "y = train['logerror'].values\n",
    "x = train.drop(['month', 'logerror'], axis=1)\n",
    "print \"Size of the train data frame: \", x.shape\n",
    "print \"Size of the prop  data frame: \", prop.shape\n",
    "\n",
    "print(\"Generate a list of outliers should be droped for training\")\n",
    "index_hi = y > hi_train\n",
    "index_lo = y < lo_train\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_train = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_train.append(ii)\n",
    "\n",
    "print(\"Generate a list of outliers should be droped for testing\")\n",
    "index_hi = y > hi_test\n",
    "index_lo = y < lo_test\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_test = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_test.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 100000):\n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(i*chunkSize)\n",
    "    listOfDf.append(len(df))\n",
    "    return listOfDf\n",
    "\n",
    "split_index = splitDataFrameIntoSmaller(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without outliers for the  1  fold is  0.0647679709375\n",
      "Score without outliers for the  2  fold is  0.0657277238894\n",
      "Score without outliers for the  3  fold is  0.0644547384655\n",
      "Score without outliers for the  4  fold is  0.0652583988152\n",
      "Score without outliers for the  5  fold is  0.0644142335129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cf6db69ba7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_parcel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprop_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/catboost/core.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, weight, ntree_limit, verbose)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \"\"\"\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RawFormulaVal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/catboost/core.pyc\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, weight, prediction_type, ntree_limit, verbose)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MultiClass'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Probability'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 44)\n",
    "\n",
    "train_pred = np.zeros(train.shape[0], dtype=np.float16)\n",
    "prop_pred = np.zeros(prop.shape[0], dtype=np.float16)\n",
    "scores1 = []; scores2 = []\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "\n",
    "    train_index_wo = [ix for ix in train_index if ix not in outliers_train]\n",
    "    test_index_wo = [ix for ix in test_index if ix not in outliers_test]\n",
    "\n",
    "    x1, x0 = x.iloc[train_index_wo], x.iloc[test_index_wo]\n",
    "    y1, y0 = y[train_index_wo], y[test_index_wo]\n",
    "\n",
    "    model.fit(x1.drop([\"id_parcel\"], axis=1), y1) # Train the model without outliers\n",
    "\n",
    "    #calculate score without second outliers\n",
    "    scores1.append(mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\"], axis=1))))\n",
    "    print \"Score without outliers for the \", len(scores1), \" fold is \", scores1[len(scores1)-1]\n",
    "\n",
    "    #calculate score with outliers\n",
    "    x0 = x.iloc[test_index]\n",
    "    y0 = y[test_index]\n",
    "\n",
    "    pred = model.predict(x0.drop([\"id_parcel\"], axis=1))\n",
    "    scores2.append(mean_absolute_error(y0, pred))\n",
    "#    print \"Score with outliers for the \", len(scores2), \" fold is \", scores2[len(scores2)-1]\n",
    "\n",
    "    for ii, idx in enumerate(test_index):\n",
    "        train_pred[idx] = pred[ii]\n",
    "\n",
    "    for ii in range(0, len(split_index)-1):\n",
    "        n1 = split_index[ii]; n2 = split_index[ii+1]\n",
    "        pred = model.predict(prop.iloc[n1:n2].drop(['id_parcel'], axis=1))\n",
    "        prop_pred[n1:n2] += pred\n",
    "\n",
    "print \"Average score without outliers over all folds : \" , np.mean(scores1), \" \", np.std(scores1)\n",
    "print \"Average score with    outliers over all folds : \" , np.mean(scores2), \" \", np.std(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame()\n",
    "out[\"ParcelId\"] = prop[\"id_parcel\"]\n",
    "months = [\"201610\", \"201611\", \"201612\", \"201710\", \"201711\", \"201712\"]\n",
    "for col in months:\n",
    "    out[col] = map(lambda x: x/10.0, prop_pred)\n",
    "    \n",
    "out_train = pd.DataFrame()\n",
    "out_train[\"ParcelId\"] = train[\"id_parcel\"]\n",
    "for col in months:\n",
    "    out_train[col] = train_pred #+ 0.02 #IMPORTANT POINT: I add a constant to train prediction\n",
    "\n",
    "\n",
    "print(\"Read the missing\")\n",
    "miss = store[\"miss\"]\n",
    "\n",
    "med = train.logerror.median()\n",
    "for col in months:\n",
    "    miss[col] = med\n",
    "    \n",
    "miss = miss[[\"id_parcel\"]+months]\n",
    "miss.columns = [\"ParcelId\"] + months\n",
    "\n",
    "out = pd.concat([out, out_train, miss], axis=0)\n",
    "\n",
    "from datetime import datetime\n",
    "out.to_csv('cat.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
