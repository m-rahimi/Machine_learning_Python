{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took  38.8257939816  seconds to read the dataframes\n"
     ]
    }
   ],
   "source": [
    "store = pd.HDFStore('../Data/store_2016.h5')\n",
    "t1 = time.time()\n",
    "train = store[\"train\"]\n",
    "prop = store[\"prop\"]\n",
    "t2 = time.time()\n",
    "print 'it took ', t2-t1, ' seconds to read the dataframes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in prop.columns:\n",
    "    prop[col]=prop[col].fillna(-1)\n",
    "    train[col]=train[col].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop = prop.replace([np.inf, -np.inf], 10000)\n",
    "train = train.replace([np.inf, -np.inf], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "0.264 -0.252\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "interval = q3 - q1\n",
    "fac = 8.0\n",
    "interval = interval * fac / 2.\n",
    "hi = interval + mid\n",
    "lo = -interval + mid\n",
    "print hi, lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the x1 data frame:  (81635, 262)\n",
      "Size of the x0 data frame:  (8515, 262)\n",
      "2084 1431\n",
      "Size of the x1 data frame:  (78120, 262)\n",
      "Size of the x0 data frame:  (8515, 262)\n"
     ]
    }
   ],
   "source": [
    "# split the data to 9 months for train and 3 months for test\n",
    "x1 = train[train.month < 10]    # use for train\n",
    "x0 = train[train.month > 9]     # use for test\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape\n",
    "\n",
    "y1 = x1['logerror'].values\n",
    "y0 = x0['logerror'].values\n",
    "\n",
    "index_hi = y1 > hi   # drop 1480 points \n",
    "index_lo = y1 < lo    # drop 947 points\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "y1 = y1[(~index_lo) & (~index_hi)]\n",
    "x1 = x1[(~index_lo) & (~index_hi)]\n",
    "\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cores 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "ncpu = multiprocessing.cpu_count()\n",
    "print \"number of cores \" + str(ncpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.recurrent import LSTM\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dims = x1.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "    model = Sequential()\n",
    "    # Input layer with dimension input_dims and hidden layer i with input_dims neurons. \n",
    "    model.add(Dense(input_dims, input_dim=input_dims, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    # Hidden layer\n",
    "    model.add(Dense(input_dims//2, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    # Hidden layer\n",
    "    model.add(Dense(input_dims//4, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    \n",
    "    # Output Layer.\n",
    "    model.add(Dense(1))\n",
    "    # Use a large learning rate with decay and a large momentum. \n",
    "    # compile this model\n",
    "    model.compile(loss='mean_absolute_error', #'mean_squared_error', # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer='rmsprop')\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "#    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=NN_model, nb_epoch=300, batch_size=30, verbose=0)))\n",
    "model = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('mlp', <keras.wrappers.scikit_learn.KerasRegressor object at 0x7f8d0552c990>)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1), y1) # Train the model without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data  0.0456814670353\n",
      "Error on 3 months test  0.0650001437843\n"
     ]
    }
   ],
   "source": [
    "print \"Error on training data \", mean_absolute_error(y1, model.predict(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))\n",
    "print \"Error on 3 months test \", mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_3months = mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "-0.252 0.264\n",
      "-2.09025 2.10225\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "\n",
    "#fac = 8.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_train = interval + mid\n",
    "lo_train = -interval + mid\n",
    "\n",
    "fac = 65.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_test = interval + mid\n",
    "lo_test = -interval + mid\n",
    "\n",
    "print lo_train, hi_train\n",
    "print lo_test, hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data frame:  (90150, 260)\n",
      "Size of the prop  data frame:  (2883630, 260)\n",
      "Generate a list of outliers should be droped for training\n",
      "2310 1568\n",
      "Generate a list of outliers should be droped for testing\n",
      "51 46\n"
     ]
    }
   ],
   "source": [
    "y = train['logerror'].values\n",
    "x = train.drop(['month', 'logerror'], axis=1)\n",
    "print \"Size of the train data frame: \", x.shape\n",
    "print \"Size of the prop  data frame: \", prop.shape\n",
    "\n",
    "print(\"Generate a list of outliers should be droped for training\")\n",
    "index_hi = y > hi_train   \n",
    "index_lo = y < lo_train   \n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_train = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_train.append(ii)\n",
    "        \n",
    "print(\"Generate a list of outliers should be droped for testing\")\n",
    "index_hi = y > hi_test   \n",
    "index_lo = y < lo_test   \n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_test = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_test.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 100000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(i*chunkSize)\n",
    "    listOfDf.append(len(df))\n",
    "    return listOfDf\n",
    "\n",
    "split_index = splitDataFrameIntoSmaller(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without outliers for the  1  fold is  0.0672507936222\n",
      "Score without outliers for the  2  fold is  0.0655911345031\n",
      "Score without outliers for the  3  fold is  0.0659643245308\n",
      "Score without outliers for the  4  fold is  0.0647205998296\n",
      "Score without outliers for the  5  fold is  0.0641033918102\n",
      "Score without outliers for the  6  fold is  0.0629652857769\n",
      "Score without outliers for the  7  fold is  0.0642480338151\n",
      "Score without outliers for the  8  fold is  0.0637069929711\n",
      "Score without outliers for the  9  fold is  0.0635517238108\n",
      "Score without outliers for the  10  fold is  0.0628664202224\n",
      "Score without outliers for the  11  fold is  0.0670981526585\n",
      "Score without outliers for the  12  fold is  0.0657553239103\n",
      "Score without outliers for the  13  fold is  0.0658620694301\n",
      "Score without outliers for the  14  fold is  0.0645993872566\n",
      "Score without outliers for the  15  fold is  0.0642916278935\n",
      "Score without outliers for the  16  fold is  0.0630057312579\n",
      "Score without outliers for the  17  fold is  0.0642605442471\n",
      "Score without outliers for the  18  fold is  0.063654904485\n",
      "Score without outliers for the  19  fold is  0.0636024363679\n",
      "Score without outliers for the  20  fold is  0.0630071393003\n",
      "Score without outliers for the  21  fold is  0.067150547008\n",
      "Score without outliers for the  22  fold is  0.0663547422244\n",
      "Score without outliers for the  23  fold is  0.0660726709569\n",
      "Score without outliers for the  24  fold is  0.0645332545136\n",
      "Score without outliers for the  25  fold is  0.0641788738179\n",
      "Score without outliers for the  26  fold is  0.0630478292903\n",
      "Score without outliers for the  27  fold is  0.0642985977837\n",
      "Score without outliers for the  28  fold is  0.0636695061347\n",
      "Score without outliers for the  29  fold is  0.0634837414754\n",
      "Score without outliers for the  30  fold is  0.0630745155993\n",
      "Score without outliers for the  31  fold is  0.0671074951881\n",
      "Score without outliers for the  32  fold is  0.0666085838101\n",
      "Score without outliers for the  33  fold is  0.0660982353852\n",
      "Score without outliers for the  34  fold is  0.0647571934516\n",
      "Score without outliers for the  35  fold is  0.0642376054919\n",
      "Score without outliers for the  36  fold is  0.0632863979858\n",
      "Score without outliers for the  37  fold is  0.0642668357462\n",
      "Score without outliers for the  38  fold is  0.0636818856285\n",
      "Score without outliers for the  39  fold is  0.0638617081796\n",
      "Score without outliers for the  40  fold is  0.0629539480794\n",
      "Score without outliers for the  41  fold is  0.0670040911932\n",
      "Score without outliers for the  42  fold is  0.065825137897\n",
      "Score without outliers for the  43  fold is  0.0660794174328\n",
      "Score without outliers for the  44  fold is  0.0646477054436\n",
      "Score without outliers for the  45  fold is  0.064355152801\n",
      "Score without outliers for the  46  fold is  0.0630576123371\n",
      "Score without outliers for the  47  fold is  0.0644604453098\n",
      "Score without outliers for the  48  fold is  0.0637088070164\n",
      "Score without outliers for the  49  fold is  0.0637004430172\n",
      "Score without outliers for the  50  fold is  0.0626059547004\n",
      "Score without outliers for the  51  fold is  0.0670794588513\n",
      "Score without outliers for the  52  fold is  0.0656344996043\n",
      "Score without outliers for the  53  fold is  0.0658296753654\n",
      "Score without outliers for the  54  fold is  0.0648438490324\n",
      "Score without outliers for the  55  fold is  0.0644462583614\n",
      "Score without outliers for the  56  fold is  0.0631918890232\n",
      "Score without outliers for the  57  fold is  0.0643781963552\n",
      "Score without outliers for the  58  fold is  0.0636974836326\n",
      "Score without outliers for the  59  fold is  0.0635596159048\n",
      "Score without outliers for the  60  fold is  0.0628068639143\n",
      "Score without outliers for the  61  fold is  0.067061240489\n",
      "Score without outliers for the  62  fold is  0.0658874767538\n",
      "Score without outliers for the  63  fold is  0.0657834738737\n",
      "Score without outliers for the  64  fold is  0.0649672963397\n",
      "Score without outliers for the  65  fold is  0.0642243866477\n",
      "Score without outliers for the  66  fold is  0.0629299928976\n",
      "Score without outliers for the  67  fold is  0.0643591503716\n",
      "Score without outliers for the  68  fold is  0.0637543269138\n",
      "Score without outliers for the  69  fold is  0.0636913817172\n",
      "Score without outliers for the  70  fold is  0.0626505322514\n",
      "Score without outliers for the  71  fold is  0.0672947044551\n",
      "Score without outliers for the  72  fold is  0.0661648471213\n",
      "Score without outliers for the  73  fold is  0.0658856828713\n",
      "Score without outliers for the  74  fold is  0.0647610821227\n",
      "Score without outliers for the  75  fold is  0.0643904296316\n",
      "Score without outliers for the  76  fold is  0.0631022698056\n",
      "Score without outliers for the  77  fold is  0.0643840137131\n",
      "Score without outliers for the  78  fold is  0.0637286985159\n",
      "Score without outliers for the  79  fold is  0.0636356759944\n",
      "Score without outliers for the  80  fold is  0.062747828328\n",
      "Score without outliers for the  81  fold is  0.0671235946192\n",
      "Score without outliers for the  82  fold is  0.0667782301186\n",
      "Score without outliers for the  83  fold is  0.0660589315383\n",
      "Score without outliers for the  84  fold is  0.0646637592877\n",
      "Score without outliers for the  85  fold is  0.0642174837783\n",
      "Score without outliers for the  86  fold is  0.0631580118973\n",
      "Score without outliers for the  87  fold is  0.0642012713402\n",
      "Score without outliers for the  88  fold is  0.0636207750639\n",
      "Score without outliers for the  89  fold is  0.0637201162719\n",
      "Score without outliers for the  90  fold is  0.0626972084254\n",
      "Score without outliers for the  91  fold is  0.0671087803956\n",
      "Score without outliers for the  92  fold is  0.0657564967768\n",
      "Score without outliers for the  93  fold is  0.0659114758861\n",
      "Score without outliers for the  94  fold is  0.0646068557679\n",
      "Score without outliers for the  95  fold is  0.0642622755123\n",
      "Score without outliers for the  96  fold is  0.0629650076978\n",
      "Score without outliers for the  97  fold is  0.0644407324003\n",
      "Score without outliers for the  98  fold is  0.0636400486708\n",
      "Score without outliers for the  99  fold is  0.0636799929004\n",
      "Score without outliers for the  100  fold is  0.0628433519923\n",
      "Average score without outliers over all folds :  0.064566016338   0.00133970879952\n",
      "Average score with    outliers over all folds :  0.0673180939743   0.0018846818685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 44)\n",
    "\n",
    "train_pred = np.zeros(train.shape[0], dtype=np.float16)\n",
    "prop_pred = np.zeros(prop.shape[0], dtype=np.float16)\n",
    "scores1 = []; scores2 = []\n",
    "\n",
    "N = 10\n",
    "for _ in range(N):\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "\n",
    "        train_index_wo = [ix for ix in train_index if ix not in outliers_train]\n",
    "        test_index_wo = [ix for ix in test_index if ix not in outliers_test]\n",
    "\n",
    "        x1, x0 = x.iloc[train_index_wo], x.iloc[test_index_wo]\n",
    "        y1, y0 = y[train_index_wo], y[test_index_wo]\n",
    "\n",
    "        model.fit(x1.drop([\"id_parcel\"], axis=1), y1) # Train the model without outliers\n",
    "\n",
    "        #calculate score without second outliers\n",
    "        scores1.append(mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\"], axis=1))))\n",
    "        print \"Score without outliers for the \", len(scores1), \" fold is \", scores1[len(scores1)-1]\n",
    "\n",
    "        #calculate score with outliers\n",
    "        x0 = x.iloc[test_index]\n",
    "        y0 = y[test_index]\n",
    "\n",
    "        pred = model.predict(x0.drop([\"id_parcel\"], axis=1))\n",
    "        scores2.append(mean_absolute_error(y0, pred))\n",
    "    #    print \"Score with outliers for the \", len(scores2), \" fold is \", scores2[len(scores2)-1]\n",
    "\n",
    "        for ii, idx in enumerate(test_index):\n",
    "            train_pred[idx] = pred[ii]\n",
    "\n",
    "        for ii in range(0, len(split_index)-1):\n",
    "            n1 = split_index[ii]; n2 = split_index[ii+1]\n",
    "            pred = model.predict(prop.iloc[n1:n2].drop(['id_parcel'], axis=1))\n",
    "            prop_pred[n1:n2] += pred\n",
    "    \n",
    "print \"Average score without outliers over all folds : \" , np.mean(scores1), \" \", np.std(scores1)\n",
    "print \"Average score with    outliers over all folds : \" , np.mean(scores2), \" \", np.std(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the missing\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame()\n",
    "out[\"ParcelId\"] = prop[\"id_parcel\"]\n",
    "months = [\"201610\", \"201611\", \"201612\", \"201710\", \"201711\", \"201712\"]\n",
    "for col in months:\n",
    "    out[col] = map(lambda x: x/(N*10.0), prop_pred)\n",
    "    \n",
    "out_train = pd.DataFrame()\n",
    "out_train[\"ParcelId\"] = train[\"id_parcel\"]\n",
    "for col in months:\n",
    "    out_train[col] = train_pred #+ 0.02 #IMPORTANT POINT: I add a constant to train prediction\n",
    "\n",
    "\n",
    "print(\"Read the missing\")\n",
    "miss = store[\"miss\"]\n",
    "\n",
    "med = train.logerror.median()\n",
    "for col in months:\n",
    "    miss[col] = med\n",
    "    \n",
    "miss = miss[[\"id_parcel\"]+months]\n",
    "miss.columns = [\"ParcelId\"] + months\n",
    "\n",
    "out = pd.concat([out, out_train, miss], axis=0)\n",
    "\n",
    "from datetime import datetime\n",
    "out.to_csv('NN.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "      <td>2.985217e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.332586e+07</td>\n",
       "      <td>5.789151e-03</td>\n",
       "      <td>5.789151e-03</td>\n",
       "      <td>5.789151e-03</td>\n",
       "      <td>5.789151e-03</td>\n",
       "      <td>5.789151e-03</td>\n",
       "      <td>5.789151e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.909966e+06</td>\n",
       "      <td>2.293646e-02</td>\n",
       "      <td>2.293646e-02</td>\n",
       "      <td>2.293646e-02</td>\n",
       "      <td>2.293646e-02</td>\n",
       "      <td>2.293646e-02</td>\n",
       "      <td>2.293646e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.071172e+07</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "      <td>-5.784375e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.164371e+07</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "      <td>-1.000214e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.254509e+07</td>\n",
       "      <td>4.934082e-03</td>\n",
       "      <td>4.934082e-03</td>\n",
       "      <td>4.934082e-03</td>\n",
       "      <td>4.934082e-03</td>\n",
       "      <td>4.934082e-03</td>\n",
       "      <td>4.934082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.409712e+07</td>\n",
       "      <td>1.026367e-02</td>\n",
       "      <td>1.026367e-02</td>\n",
       "      <td>1.026367e-02</td>\n",
       "      <td>1.026367e-02</td>\n",
       "      <td>1.026367e-02</td>\n",
       "      <td>1.026367e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.696019e+08</td>\n",
       "      <td>1.140000e+01</td>\n",
       "      <td>1.140000e+01</td>\n",
       "      <td>1.140000e+01</td>\n",
       "      <td>1.140000e+01</td>\n",
       "      <td>1.140000e+01</td>\n",
       "      <td>1.140000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ParcelId        201610        201611        201612        201710  \\\n",
       "count  2.985217e+06  2.985217e+06  2.985217e+06  2.985217e+06  2.985217e+06   \n",
       "mean   1.332586e+07  5.789151e-03  5.789151e-03  5.789151e-03  5.789151e-03   \n",
       "std    7.909966e+06  2.293646e-02  2.293646e-02  2.293646e-02  2.293646e-02   \n",
       "min    1.071172e+07 -5.784375e-01 -5.784375e-01 -5.784375e-01 -5.784375e-01   \n",
       "25%    1.164371e+07 -1.000214e-04 -1.000214e-04 -1.000214e-04 -1.000214e-04   \n",
       "50%    1.254509e+07  4.934082e-03  4.934082e-03  4.934082e-03  4.934082e-03   \n",
       "75%    1.409712e+07  1.026367e-02  1.026367e-02  1.026367e-02  1.026367e-02   \n",
       "max    1.696019e+08  1.140000e+01  1.140000e+01  1.140000e+01  1.140000e+01   \n",
       "\n",
       "             201711        201712  \n",
       "count  2.985217e+06  2.985217e+06  \n",
       "mean   5.789151e-03  5.789151e-03  \n",
       "std    2.293646e-02  2.293646e-02  \n",
       "min   -5.784375e-01 -5.784375e-01  \n",
       "25%   -1.000214e-04 -1.000214e-04  \n",
       "50%    4.934082e-03  4.934082e-03  \n",
       "75%    1.026367e-02  1.026367e-02  \n",
       "max    1.140000e+01  1.140000e+01  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443211479551 0.448271219867\n"
     ]
    }
   ],
   "source": [
    "print score_3months, np.mean(scores1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
