{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the properties and merge with coord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (33,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2985217, 58)\n"
     ]
    }
   ],
   "source": [
    "path = \"../Zillow2/Data/\"\n",
    "print(\"Read the properties and merge with coord\")\n",
    "prop = pd.read_csv(path + 'renamed_properties_2016.csv')\n",
    "prop = prop.drop(\"id\", axis=1)\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2985217, 55)\n"
     ]
    }
   ],
   "source": [
    "# drop two constant features and fips\n",
    "prop = prop.drop([\"flag_tub\", \"flag_fireplace\", \"fips\"], axis=1)\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the properties data frame:  (2973780, 55)\n"
     ]
    }
   ],
   "source": [
    "# Drop missing rows from prop\n",
    "index = pd.isnull(prop[\"latitude\"])\n",
    "prop = prop[~index]\n",
    "print \"Size of the properties data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# clasify features to three classes\n",
    "number = [\"num_bathroom\", \"num_bedroom\", \"num_bathroom_calc\", \"num_fireplace\", \"num_bath\", \"num_garage\", \"num_pool\", \n",
    "          \"num_room\", \"num_75_bath\", \"num_unit\", \"num_story\"]\n",
    "quality = [\"type_aircon\", \"type_architectural\", \"type_framing\", \"type_quality\", \"type_deck\", \"type_heating\", \n",
    "           \"pooltypeid10\", \"pooltypeid2\", \"pooltypeid7\", \"type_zoning_landuse\", \"type_story\", \"type_material\"]\n",
    "position = [\"region_city\", \"region_county\", \"region_neighbor\", \"region_zip\", \"zoning_landuse_county\", \n",
    "             \"zoning_property\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "tax3 = [\"tax_delinquency\"]\n",
    "ll = number + quality + position + tax3\n",
    "\n",
    "print len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prop[\"miss_val\"] = prop.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train file to obtain some statistic about the features and target\n",
      "Size of the train data frame:  (90275, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"Read train file to obtain some statistic about the features and target\")\n",
    "train = pd.read_csv(path + 'renamed_train_2016.csv', parse_dates=['date'])\n",
    "train = train.drop(\"id\", axis=1)\n",
    "\n",
    "train[\"month\"] = train['date'].dt.month\n",
    "\n",
    "train = pd.merge(train, prop, how='left', on='id_parcel')\n",
    "\n",
    "train = train.drop(['id_parcel', 'date'], axis=1)\n",
    "print \"Size of the train data frame: \", train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop['latitude'] = prop['latitude'] / 1e6\n",
    "prop['longitude'] = prop['longitude'] / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_bathroom              25\n",
       "num_bedroom               13\n",
       "num_bathroom_calc     117475\n",
       "num_fireplace        2661143\n",
       "num_bath              117475\n",
       "num_garage           2090513\n",
       "num_pool             2456246\n",
       "num_room                  38\n",
       "num_75_bath          2662149\n",
       "num_unit              996290\n",
       "num_story            2291711\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = [\"num_bathroom\", \"num_bedroom\", \"num_bathroom_calc\", \"num_fireplace\", \"num_bath\", \"num_garage\", \"num_pool\", \n",
    "          \"num_room\", \"num_75_bath\", \"num_unit\", \"num_story\"]\n",
    "pd.isnull(prop[number]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_bathroom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  14\n",
      "num_bedroom\n",
      "Number of classes:  11\n",
      "num_bathroom_calc\n",
      "Number of classes:  14\n",
      "num_fireplace\n",
      "Number of classes:  6\n",
      "num_bath\n",
      "Number of classes:  9\n",
      "num_garage\n",
      "Number of classes:  7\n",
      "num_pool\n",
      "Number of classes:  3\n",
      "num_room\n",
      "Number of classes:  11\n",
      "num_75_bath\n",
      "Number of classes:  4\n",
      "num_unit\n",
      "Number of classes:  7\n",
      "num_story\n",
      "Number of classes:  6\n"
     ]
    }
   ],
   "source": [
    "# Combine the rare events to avoid overfit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fix_number(target, threshold = 200, na_value = 0):\n",
    "    \n",
    "    X = train[target].fillna(na_value)\n",
    "    max_target = 10000000\n",
    "    \n",
    "    density = X.value_counts()\n",
    "    index = density.index\n",
    "    rare = density[density < threshold].index\n",
    "    X.loc[X.isin(rare)] = max_target\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X))\n",
    "#    train[target] = lbl.transform(list(X))\n",
    "    \n",
    "    Y = pd.DataFrame(prop[[\"id_parcel\", target]])\n",
    "    Y[target] = Y[target].fillna(na_value)\n",
    "    \n",
    "    known = Y[target].isin(index)\n",
    "    Y_known = Y[known]\n",
    "    Y_unknown = Y[~known]\n",
    "    \n",
    "    Y_known.loc[Y_known[target].isin(rare), target] = max_target\n",
    "    Y_known.loc[:, target] = lbl.transform(Y_known[target].values)\n",
    "    \n",
    "    print \"Number of classes: \", Y_known.loc[:, target].max() + 2\n",
    "    Y_unknown.loc[:, target] = Y_known.loc[:, target].max() + 1\n",
    "    \n",
    "    prop.loc[known, target] = Y_known[target].values\n",
    "    prop.loc[~known, target] = Y_unknown[target].values\n",
    "\n",
    "# I assumed all NaN values are zeros\n",
    "for ii in number:\n",
    "    print ii\n",
    "    fix_number(ii, threshold = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_aircon           2162261\n",
       "type_architectural    2967719\n",
       "type_framing          2961151\n",
       "type_quality          1035292\n",
       "type_deck             2956684\n",
       "type_heating          1167379\n",
       "pooltypeid10          2936841\n",
       "pooltypeid2           2941705\n",
       "pooltypeid7           2488321\n",
       "type_story            2972156\n",
       "type_material         2967033\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality = [\"type_aircon\", \"type_architectural\", \"type_framing\", \"type_quality\", \"type_deck\", \"type_heating\", \n",
    "           \"pooltypeid10\", \"pooltypeid2\", \"pooltypeid7\", \"type_story\", \"type_material\"]\n",
    "pd.isnull(prop[quality]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  6\n",
      "Number of classes:  4\n",
      "Number of classes:  3\n",
      "Number of classes:  7\n",
      "Number of classes:  3\n",
      "Number of classes:  7\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  3\n",
      "Number of classes:  4\n"
     ]
    }
   ],
   "source": [
    "# I assumed all NaN values as a new group\n",
    "for ii in quality:\n",
    "    fix_number(ii, threshold = 200, na_value = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_city                 51408\n",
       "region_county                   0\n",
       "region_neighbor           1817378\n",
       "region_zip                   2543\n",
       "zoning_landuse_county         840\n",
       "type_zoning_landuse             0\n",
       "zoning_property            995151\n",
       "censustractandblock         63689\n",
       "rawcensustractandblock          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position exclude latitude and longitude\n",
    "position = [\"region_city\", \"region_county\", \"region_neighbor\", \"region_zip\", \"zoning_landuse_county\", \n",
    "            \"type_zoning_landuse\", \"zoning_property\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "\n",
    "pd.isnull(prop[position]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fillna_knn(target, k=100):\n",
    "    gps = ['latitude', 'longitude']\n",
    "    \n",
    "    index = pd.isnull(prop[target])\n",
    "    Y = prop.loc[index, gps]\n",
    "    X = prop.loc[~index, [target] + gps]\n",
    "\n",
    "    print \"Size of the missing data: \", Y.shape\n",
    "    print \"Size of the data: \", X.shape\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X[target].values))\n",
    "    X[target] = lbl.transform(list(X[target].values))\n",
    "\n",
    "    print \"Number of classes: \", X[target].max() + 1\n",
    "    \n",
    "    clf = neighbors.KNeighborsClassifier( n_neighbors = k, weights = 'uniform', n_jobs = 8 )\n",
    "    clf.fit(X.drop(target, axis=1), X[target])\n",
    "    \n",
    "    Y[target] = clf.predict(Y)\n",
    "    \n",
    "    prop.loc[index, target] = Y[target].values\n",
    "    prop.loc[~index, target] = X[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_zip\n",
      "Size of the missing data:  (2543, 2)\n",
      "Size of the data:  (2971237, 3)\n",
      "Number of classes:  405\n",
      "zoning_landuse_county\n",
      "Size of the missing data:  (840, 2)\n",
      "Size of the data:  (2972940, 3)\n",
      "Number of classes:  240\n"
     ]
    }
   ],
   "source": [
    "# impute missing value\n",
    "position_miss = [\"region_zip\", \"zoning_landuse_county\"]\n",
    "for ii in position_miss:\n",
    "    print ii\n",
    "    fillna_knn(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert object features to int\n"
     ]
    }
   ],
   "source": [
    "# convert object features to int\n",
    "object_type = [\"zoning_property\", \"zoning_landuse_county\"]\n",
    "print(\"convert object features to int\")\n",
    "for c in object_type:\n",
    "    prop[c]=prop[c].fillna(-2)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(prop[c].values))\n",
    "    prop[c] = lbl.transform(list(prop[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert region features to int\n"
     ]
    }
   ],
   "source": [
    "# impute missing value; missing value as a new group\n",
    "region = [\"region_zip\", \"region_city\", \"region_county\", \"region_neighbor\", \"type_zoning_landuse\", \"censustractandblock\", \"rawcensustractandblock\"]\n",
    "print(\"convert region features to int\")\n",
    "for c in region:\n",
    "    prop[c]=prop[c].fillna(-2)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(prop[c].values))\n",
    "    prop[c] = lbl.transform(list(prop[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the missing data:  (48491, 2)\n",
      "Size of the data:  (2925289, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def fillna_knn_reg(target, k=100):\n",
    "    gps = ['latitude', 'longitude']\n",
    "    \n",
    "    index = pd.isnull(prop[target])\n",
    "    Y = prop.loc[index, gps]\n",
    "    X = prop.loc[~index, [target] + gps]\n",
    "\n",
    "    print \"Size of the missing data: \", Y.shape\n",
    "    print \"Size of the data: \", X.shape\n",
    "       \n",
    "    clf = neighbors.KNeighborsRegressor( n_neighbors = k, weights = 'uniform' )\n",
    "    clf.fit(X.drop(target, axis=1), X[target])\n",
    "    \n",
    "    Y[target] = clf.predict(Y)\n",
    "    \n",
    "    prop.loc[index, target] = Y[target].values\n",
    "    prop.loc[~index, target] = X[target].values\n",
    "    \n",
    "fillna_knn_reg(\"build_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "# convert data type to reduce the size\n",
    "for c in number:\n",
    "    prop[c] = prop[c].astype(np.int8)\n",
    "    \n",
    "for c in quality:\n",
    "    prop[c] = prop[c].astype(np.int8)\n",
    "    \n",
    "for c in position:\n",
    "    prop[c] = prop[c].astype(np.int16)\n",
    "    \n",
    "print('Binding to float32')\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add new features\n",
    "# Hadi can add more features hear to improve the code\n",
    "prop[\"area_ratio\"] = prop[\"area_total_calc\"] / prop[\"area_lot\"]\n",
    "prop[\"tax_building_area\"] = prop[\"tax_building\"] / (prop[\"area_lot\"])\n",
    "prop[\"tax_property_area\"] = prop[\"tax_property\"] / (prop[\"area_lot\"])\n",
    "\n",
    "prop[\"tax_total_property\"] = prop[\"tax_total\"] / prop[\"tax_property\"]\n",
    "prop[\"tax_totalproperty\"] = prop[\"tax_total\"] * prop[\"tax_property\"]\n",
    "prop[\"tax_building_land\"] = prop[\"tax_building\"] / prop[\"tax_land\"]\n",
    "\n",
    "prop[\"area_total_firstfloor\"] = prop[\"area_total_calc\"] / prop[\"area_firstfloor_finished\"]\n",
    "\n",
    "prop[\"lat_lon\"] = prop[\"latitude\"] / prop[\"longitude\"]\n",
    "prop[\"latlon\"] = prop[\"latitude\"] * prop[\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average value of selected features in different region and then\n",
    "# calculate the difference between average and exact value\n",
    "ll1 = ['region_zip', 'region_neighbor', 'zoning_landuse_county', 'region_city']\n",
    "ll2 = ['zip', 'neighbor', 'zon', 'city']\n",
    "fea = [\"area_lot\", \"area_total_calc\", \"tax_building\",  \"tax_property\", \"latitude\", \"longitude\", \"tax_total\",\n",
    "       \"tax_property_area\", \"tax_building_area\", \"build_year\", \"num_bedroom\", \"num_bathroom\"]\n",
    "\n",
    "for c1, c2 in zip(ll1, ll2):\n",
    "    for cc in fea:\n",
    "        ave = prop.groupby(c1)[cc].mean().to_dict()\n",
    "        name1 = c2 + \"_\" + cc\n",
    "        prop[name1] = prop[c1].map(ave)\n",
    "        name2 = name1 + \"_diff\"\n",
    "        prop[name2] = prop[cc] - prop[name1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of house in each region\n",
    "ll = ['region_zip', 'region_city', 'region_neighbor', 'type_zoning_landuse']\n",
    "for c in ll:\n",
    "    count = prop[c].value_counts().to_dict()\n",
    "    name = c + \"_count\"\n",
    "    prop[name] = prop[c].map(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read location file\n",
      "(2973780, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I convert the coordinate from cartesian to polar coordinate\n",
    "print \"Read location file\"\n",
    "coord = pd.read_csv(path + \"location2.csv\")\n",
    "print coord.shape\n",
    "\n",
    "prop = pd.merge(prop, coord.drop([\"latitude\", \"longitude\"], axis = 1), how='left', on='id_parcel')\n",
    "del coord\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2973780 entries, 0 to 2973779\n",
      "Columns: 177 entries, id_parcel to num_rot75_Y\n",
      "dtypes: float32(31), float64(108), int16(9), int64(7), int8(22)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "print('Binding to float32')\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2973780 entries, 0 to 2973779\n",
      "Columns: 177 entries, id_parcel to num_rot75_Y\n",
      "dtypes: float32(139), int16(9), int64(7), int8(22)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read cluster file\n",
      "(2973780, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I used kmean and split the data to new clusters based on lat and lon\n",
    "print \"Read cluster file\"\n",
    "clusters = pd.read_csv(path + \"n_clusters2.csv\")\n",
    "print clusters.shape\n",
    "\n",
    "prop = pd.merge(prop, clusters, how='left', on='id_parcel')\n",
    "del clusters\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = ['cluster0', 'cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5']\n",
    "for c in clusters:\n",
    "    count = prop[c].value_counts().to_dict()\n",
    "    name = c + \"_count\"\n",
    "    prop[name] = prop[c].map(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = ['cluster1', 'cluster2', 'cluster3'] #, 'cluster1', 'cluster2', 'cluster3', 'cluster4']\n",
    "clusters2 = ['cl1', 'cl2', 'cl3'] #, 'cl1', 'cl2', 'cl3', 'cl4']\n",
    "    \n",
    "fea = [\"area_lot\", \"area_total_calc\", \"tax_building\",  \"tax_property\", \"latitude\", \"longitude\", \"tax_total\",\n",
    "       \"tax_property_area\", \"tax_building_area\", \"build_year\", \"num_bedroom\", \"num_bathroom\"]\n",
    "\n",
    "for c1, c2 in zip(clusters, clusters2):\n",
    "    for cc in fea:\n",
    "        ave = prop.groupby(c1)[cc].mean().to_dict()\n",
    "        name1 = c2 + \"_\" + cc\n",
    "        prop[name1] = prop[c1].map(ave)\n",
    "        name2 = name1 + \"_diff\"\n",
    "        prop[name2] = prop[cc] - prop[name1]\n",
    "        \n",
    "        prop[name1] = prop[name1].astype(np.float32)\n",
    "        prop[name2] = prop[name2].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2973780 entries, 0 to 2973779\n",
      "Columns: 261 entries, id_parcel to cl3_num_bathroom_diff\n",
      "dtypes: float32(211), int16(9), int64(19), int8(22)\n",
      "memory usage: 2.9 GB\n"
     ]
    }
   ],
   "source": [
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train file and merge with properties to generate train file and taraget\n",
      "Size of the train data frame:  (90275, 263)\n"
     ]
    }
   ],
   "source": [
    "# Read Train\n",
    "print(\"Read train file and merge with properties to generate train file and taraget\")\n",
    "train = pd.read_csv(path + 'renamed_train_2016.csv', parse_dates=['date'])\n",
    "train = train.drop(\"id\", axis=1)\n",
    "\n",
    "train[\"month\"] = train['date'].dt.month\n",
    "\n",
    "train = pd.merge(train, prop, how='left', on='id_parcel')\n",
    "train = train.drop(['date'], axis=1)\n",
    "print \"Size of the train data frame: \", train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2883630 entries, 0 to 2883629\n",
      "Columns: 261 entries, id_parcel to cl3_num_bathroom_diff\n",
      "dtypes: float32(211), int16(9), int64(19), int8(22)\n",
      "memory usage: 2.8 GB\n"
     ]
    }
   ],
   "source": [
    "# Exclude train from prop\n",
    "id_parcel = train[\"id_parcel\"].values\n",
    "prop = prop.set_index(\"id_parcel\")\n",
    "prop = prop.drop(id_parcel)\n",
    "prop = prop.reset_index()\n",
    "prop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the missing\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11437 entries, 0 to 11436\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    11437 non-null int64\n",
      "index         11437 non-null int64\n",
      "id_parcel     11437 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 268.1 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Read the missing\")\n",
    "miss = pd.read_csv(path + 'missing.csv')\n",
    "miss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = pd.HDFStore('Data/store2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store[\"prop\"] = prop\n",
    "store[\"train\"] = train\n",
    "store[\"miss\"] = miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: Data/store3.h5\n",
      "/miss             frame        (shape->[11437,3])    \n",
      "/prop             frame        (shape->[2883630,261])\n",
      "/train            frame        (shape->[90275,263])  \n"
     ]
    }
   ],
   "source": [
    "print store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
