{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncpu = 8 # It should be modified if run of midawy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: ../Data/store1.h5\n",
      "/miss             frame        (shape->[11437,3])    \n",
      "/prop             frame        (shape->[2883630,254])\n",
      "/train            frame        (shape->[90275,256])  \n"
     ]
    }
   ],
   "source": [
    "store = pd.HDFStore('../Data/store1.h5')\n",
    "print store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = store[\"train\"]\n",
    "prop = store[\"prop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop shape (2883630, 236)\n",
      "train shape (90275, 238)\n"
     ]
    }
   ],
   "source": [
    "dd = ['type_architectural',\n",
    " 'area_basement',\n",
    " 'num_bathroom',\n",
    " 'num_bedroom',\n",
    " 'type_framing',\n",
    " 'num_bathroom_calc',\n",
    " 'type_deck',\n",
    " 'area_liveperi_finished',\n",
    " 'num_bath',\n",
    " 'pooltypeid10',\n",
    " 'region_county',\n",
    " 'type_story',\n",
    " 'type_material',\n",
    " 'area_shed',\n",
    " 'tax_year',\n",
    " 'num_rot75_X',\n",
    " 'num_rot75_Y']\n",
    "\n",
    "train = train.drop(dd + [\"area_total_calc\"], axis=1)\n",
    "prop = prop.drop(dd + [\"area_total_calc\"], axis=1)\n",
    "\n",
    "print \"prop shape \" + str(prop.shape)\n",
    "print \"train shape \" + str(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop shape (2883630, 101)\n",
      "train shape (90275, 103)\n"
     ]
    }
   ],
   "source": [
    "important = ['cl3_num_bedroom', 'area_total_calc', 'cl1_num_bedroom_diff',\n",
    "       'zip_tax_property_diff', 'num_rot30_X', 'city_num_bedroom_diff',\n",
    "       'zon_build_year', 'cl3_tax_building_area_diff', 'tax_property_area',\n",
    "       'neighbor_latitude_diff', 'neighbor_tax_property_area_diff',\n",
    "       'cl3_num_bedroom_diff', 'num_pool', 'cluster3',\n",
    "       'cl3_num_bathroom_diff', 'cl2_num_bedroom_diff',\n",
    "       'region_city_count', 'neighbor_tax_building_diff',\n",
    "       'cl2_tax_total_diff', 'cl1_tax_total_diff',\n",
    "       'cl3_tax_property_area_diff', 'cl3_tax_total_diff',\n",
    "       'zip_build_year', 'area_total_finished', 'cl2_area_lot_diff',\n",
    "       'city_build_year_diff', 'zon_num_bedroom_diff',\n",
    "       'cl2_area_total_calc_diff', 'city_tax_property_diff',\n",
    "       'neighbor_tax_property_diff', 'city_tax_property_area_diff',\n",
    "       'cl1_tax_property_area_diff', 'region_zip', 'cl1_area_lot_diff',\n",
    "       'zon_longitude_diff', 'region_zip_count',\n",
    "       'cl3_area_total_calc_diff', 'zip_area_lot_diff', 'zoning_property',\n",
    "       'neighbor_longitude_diff', 'zon_tax_building_diff',\n",
    "       'cl2_tax_building_diff', 'cluster5', 'tax_property',\n",
    "       'zon_tax_building_area_diff', 'cl3_build_year', 'cluster4_count',\n",
    "       'cl1_tax_building_area_diff', 'zip_tax_property_area_diff',\n",
    "       'city_tax_total_diff', 'num_rot45_X', 'cl1_area_total_calc_diff',\n",
    "       'cl1_tax_building_diff', 'tax_total', 'city_longitude_diff',\n",
    "       'cl3_tax_building_diff', 'city_tax_building_diff', 'cluster4',\n",
    "       'zon_tax_property_diff', 'city_area_total_calc_diff',\n",
    "       'cl2_tax_property_area_diff', 'zip_tax_total_diff',\n",
    "       'zon_tax_property_area_diff', 'zip_longitude_diff',\n",
    "       'neighbor_tax_total_diff', 'zon_build_year_diff',\n",
    "       'zon_latitude_diff', 'cl1_build_year_diff', 'tax_building',\n",
    "       'cl3_tax_property_diff', 'neighbor_build_year_diff',\n",
    "       'cl3_area_lot_diff', 'cluster5_count', 'zip_num_bedroom_diff',\n",
    "       'zon_tax_total_diff', 'neighbor_area_lot_diff',\n",
    "       'zip_tax_building_diff', 'zip_build_year_diff', 'zip_latitude_diff',\n",
    "       'neighbor_area_total_calc_diff', 'cl3_build_year_diff',\n",
    "       'cl1_latitude_diff', 'area_lot', 'cl2_longitude_diff',\n",
    "       'cl1_tax_property_diff', 'city_latitude_diff', 'city_area_lot_diff',\n",
    "       'build_year', 'cl2_latitude_diff', 'area_ratio',\n",
    "       'cl3_latitude_diff', 'zip_area_total_calc_diff',\n",
    "       'cl2_tax_property_diff', 'cl2_build_year_diff',\n",
    "       'cl3_longitude_diff', 'cl1_longitude_diff', 'zon_area_lot_diff',\n",
    "       'tax_land', 'area_live_finished', 'zon_area_total_calc_diff']\n",
    "\n",
    "train = train[important + [\"id_parcel\", \"logerror\", \"month\"]]\n",
    "prop = prop[important + [\"id_parcel\"]]\n",
    "\n",
    "print \"prop shape \" + str(prop.shape)\n",
    "print \"train shape \" + str(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in prop.columns:\n",
    "    prop[col]=prop[col].fillna(prop[col].median())\n",
    "    train[col]=train[col].fillna(prop[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "0.264 -0.252\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "interval = q3 - q1\n",
    "fac = 8.0\n",
    "interval = interval * fac / 2.\n",
    "hi = interval + mid\n",
    "lo = -interval + mid\n",
    "print hi, lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the x1 data frame:  (81733, 103)\n",
      "Size of the x0 data frame:  (8542, 103)\n",
      "2088 1432\n",
      "Size of the x1 data frame:  (78213, 103)\n",
      "Size of the x0 data frame:  (8542, 103)\n"
     ]
    }
   ],
   "source": [
    "# split the data to 9 months for train and 3 months for test\n",
    "x1 = train[train.month < 10]    # use for train\n",
    "x0 = train[train.month > 9]     # use for test\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape\n",
    "\n",
    "y1 = x1['logerror'].values\n",
    "y0 = x0['logerror'].values\n",
    "\n",
    "index_hi = y1 > hi   # drop 1480 points\n",
    "index_lo = y1 < lo    # drop 947 points\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "y1 = y1[(~index_lo) & (~index_hi)]\n",
    "x1 = x1[(~index_lo) & (~index_hi)]\n",
    "\n",
    "print \"Size of the x1 data frame: \", x1.shape\n",
    "print \"Size of the x0 data frame: \", x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.recurrent import LSTM\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dims = x1.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "    model = Sequential()\n",
    "    # Input layer with dimension input_dims and hidden layer i with input_dims neurons. \n",
    "    model.add(Dense(input_dims, input_dim=input_dims, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    # Hidden layer\n",
    "    model.add(Dense(input_dims//2, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    # Hidden layer\n",
    "    model.add(Dense(input_dims//4, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    \n",
    "    # Output Layer.\n",
    "    model.add(Dense(1))\n",
    "    # Use a large learning rate with decay and a large momentum. \n",
    "    # compile this model\n",
    "    model.compile(loss='mean_absolute_error', #'mean_squared_error', # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer='rmsprop')\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "#    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=NN_model, nb_epoch=300, batch_size=30, verbose=0)))\n",
    "model = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data  0.0460231832904\n",
      "Error on 3 months test  0.0656488194521\n"
     ]
    }
   ],
   "source": [
    "model.fit(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1), y1) # Train the model without outliers\n",
    "\n",
    "print \"Error on training data \", mean_absolute_error(y1, model.predict(x1.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))\n",
    "print \"Error on 3 months test \", mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\", \"month\", \"logerror\"], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data frame:  (90150, 103)\n",
      "Size of the prop data frame:  (2883630, 101)\n"
     ]
    }
   ],
   "source": [
    "# we have duplicate in train :(\n",
    "# we can have three simple strategies\n",
    "# 1- keep first one; 2- keep last one; 3- average\n",
    "# I think the logerror reduce from first to last but I am not sure\n",
    "# it is a very important point\n",
    "duplicate = train[\"id_parcel\"].duplicated(keep='first')\n",
    "train = train[~duplicate]\n",
    "print \"Size of the train data frame: \", train.shape\n",
    "print \"Size of the prop data frame: \", prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0313 0.0332\n",
      "-0.252 0.264\n",
      "-2.09025 2.10225\n"
     ]
    }
   ],
   "source": [
    "y = train.logerror\n",
    "mid = np.percentile(y, 50)\n",
    "y = y - mid\n",
    "q1 = np.percentile(y, 25)\n",
    "q3 = np.percentile(y, 75)\n",
    "print q1, q3\n",
    "\n",
    "fac = 8.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_train = interval + mid\n",
    "lo_train = -interval + mid\n",
    "\n",
    "fac = 65.0\n",
    "interval = q3 - q1\n",
    "interval = interval * fac / 2.\n",
    "hi_test = interval + mid\n",
    "lo_test = -interval + mid\n",
    "\n",
    "print lo_train, hi_train\n",
    "print lo_test, hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data frame:  (90150, 101)\n",
      "Size of the prop  data frame:  (2883630, 101)\n",
      "Generate a list of outliers should be droped for training\n",
      "2310 1568\n",
      "Generate a list of outliers should be droped for testing\n",
      "51 46\n"
     ]
    }
   ],
   "source": [
    "y = train['logerror'].values\n",
    "x = train.drop(['month', 'logerror'], axis=1)\n",
    "print \"Size of the train data frame: \", x.shape\n",
    "print \"Size of the prop  data frame: \", prop.shape\n",
    "\n",
    "print(\"Generate a list of outliers should be droped for training\")\n",
    "index_hi = y > hi_train\n",
    "index_lo = y < lo_train\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_train = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_train.append(ii)\n",
    "\n",
    "print(\"Generate a list of outliers should be droped for testing\")\n",
    "index_hi = y > hi_test\n",
    "index_lo = y < lo_test\n",
    "print sum(index_hi), sum(index_lo)\n",
    "\n",
    "outliers_test = []\n",
    "for ii in range(y.shape[0]):\n",
    "    if index_hi[ii] or index_lo[ii]:\n",
    "        outliers_test.append(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 100000):\n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(i*chunkSize)\n",
    "    listOfDf.append(len(df))\n",
    "    return listOfDf\n",
    "\n",
    "split_index = splitDataFrameIntoSmaller(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without outliers for the  1  fold is  0.0676785859112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-417bcbad942a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_parcel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprop_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[1;32m    314\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amin/Software/anaconda2/lib/python2.7/site-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 44)\n",
    "\n",
    "train_pred = np.zeros(train.shape[0], dtype=np.float16)\n",
    "prop_pred = np.zeros(prop.shape[0], dtype=np.float16)\n",
    "scores1 = []; scores2 = []\n",
    "\n",
    "for _ in range(10):\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "\n",
    "        train_index_wo = [ix for ix in train_index if ix not in outliers_train]\n",
    "        test_index_wo = [ix for ix in test_index if ix not in outliers_test]\n",
    "\n",
    "        x1, x0 = x.iloc[train_index_wo], x.iloc[test_index_wo]\n",
    "        y1, y0 = y[train_index_wo], y[test_index_wo]\n",
    "\n",
    "        model.fit(x1.drop([\"id_parcel\"], axis=1), y1) # Train the model without outliers\n",
    "\n",
    "        #calculate score without second outliers\n",
    "        scores1.append(mean_absolute_error(y0, model.predict(x0.drop([\"id_parcel\"], axis=1))))\n",
    "        print \"Score without outliers for the \", len(scores1), \" fold is \", scores1[len(scores1)-1]\n",
    "\n",
    "        #calculate score with outliers\n",
    "        x0 = x.iloc[test_index]\n",
    "        y0 = y[test_index]\n",
    "\n",
    "        pred = model.predict(x0.drop([\"id_parcel\"], axis=1))\n",
    "        scores2.append(mean_absolute_error(y0, pred))\n",
    "    #    print \"Score with outliers for the \", len(scores2), \" fold is \", scores2[len(scores2)-1]\n",
    "\n",
    "        for ii, idx in enumerate(test_index):\n",
    "            train_pred[idx] = pred[ii]\n",
    "\n",
    "        for ii in range(0, len(split_index)-1):\n",
    "            n1 = split_index[ii]; n2 = split_index[ii+1]\n",
    "            pred = model.predict(prop.iloc[n1:n2].drop(['id_parcel'], axis=1))\n",
    "            prop_pred[n1:n2] += pred\n",
    "\n",
    "print \"Average score without outliers over all folds : \" , np.mean(scores1), \" \", np.std(scores1)\n",
    "print \"Average score with    outliers over all folds : \" , np.mean(scores2), \" \", np.std(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame()\n",
    "out[\"ParcelId\"] = prop[\"id_parcel\"]\n",
    "months = [\"201610\", \"201611\", \"201612\", \"201710\", \"201711\", \"201712\"]\n",
    "for col in months:\n",
    "    out[col] = map(lambda x: x/10.0, prop_pred)\n",
    "    \n",
    "out_train = pd.DataFrame()\n",
    "out_train[\"ParcelId\"] = train[\"id_parcel\"]\n",
    "for col in months:\n",
    "    out_train[col] = train_pred #+ 0.02 #IMPORTANT POINT: I add a constant to train prediction\n",
    "\n",
    "\n",
    "print(\"Read the missing\")\n",
    "miss = store[\"miss\"]\n",
    "\n",
    "med = train.logerror.median()\n",
    "for col in months:\n",
    "    miss[col] = med\n",
    "    \n",
    "miss = miss[[\"id_parcel\"]+months]\n",
    "miss.columns = [\"ParcelId\"] + months\n",
    "\n",
    "out = pd.concat([out, out_train, miss], axis=0)\n",
    "\n",
    "from datetime import datetime\n",
    "out.to_csv('rf.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
