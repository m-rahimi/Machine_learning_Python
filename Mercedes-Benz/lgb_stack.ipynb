{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"clean_train2.csv\")\n",
    "El = pd.read_csv(\"clean_train_El1.csv\")\n",
    "xgb = pd.read_csv(\"clean_train_Xgb.csv\")\n",
    "lgb = pd.read_csv(\"clean_train_Lgb.csv\")\n",
    "rf  = pd.read_csv(\"clean_train_Rf.csv\")\n",
    "ada = pd.read_csv(\"clean_train_Ada.csv\")\n",
    "gbm = pd.read_csv(\"clean_train_Gbm.csv\")\n",
    "nnt = pd.read_csv(\"clean_train_Keras.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3693, 8)\n"
     ]
    }
   ],
   "source": [
    "stack = El[[\"ID\", \"El1\"]]\n",
    "stack[\"xgb\"] = xgb.Xgboost\n",
    "stack[\"lgb\"] = lgb.Lgb\n",
    "stack[\"rf\"] = rf.Rf\n",
    "stack[\"ada\"] = ada.Ada\n",
    "stack[\"gbm\"] = gbm.Gbm\n",
    "stack[\"nnt\"] = nnt.Keras\n",
    "\n",
    "print stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train shape : ', (3693, 382))\n"
     ]
    }
   ],
   "source": [
    "y = train[\"y\"]\n",
    "train = train.drop(\"y\", axis=1)\n",
    "print(\"Train shape : \", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test shape : ', (4209, 8))\n"
     ]
    }
   ],
   "source": [
    "#test = pd.read_csv(\"clean_test2.csv\")\n",
    "El = pd.read_csv(\"clean_test_El1.csv\")\n",
    "xgb = pd.read_csv(\"clean_test_Xgb.csv\")\n",
    "lgb = pd.read_csv(\"clean_test_Lgb.csv\")\n",
    "rf  = pd.read_csv(\"clean_test_Rf.csv\")\n",
    "ada = pd.read_csv(\"clean_test_Ada.csv\")\n",
    "gbm = pd.read_csv(\"clean_test_Gbm.csv\")\n",
    "nnt = pd.read_csv(\"clean_test_Keras.csv\")\n",
    "\n",
    "test = El[[\"ID\", \"El1\"]]\n",
    "test[\"xgb\"] = xgb.Xgboost\n",
    "test[\"lgb\"] = lgb.Lgb\n",
    "test[\"rf\"] = rf.Rf\n",
    "test[\"ada\"] = ada.Ada\n",
    "test[\"gbm\"] = gbm.Gbm\n",
    "test[\"nnt\"] = nnt.Keras\n",
    "\n",
    "print(\"Test shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class LgbReg(object):\n",
    "    def __init__(self, num_iterations=10, **kwargs):\n",
    "        self.clf = None\n",
    "        self.num_iterations = num_iterations\n",
    "        self.params = kwargs\n",
    "        self.params.update({'objective': 'regression'})\n",
    " \n",
    "    def fit(self, X, y, num_iterations=None):\n",
    "        num_iterations = num_iterations or self.num_iterations\n",
    "        dtrain = lgb.Dataset(X, label= y)\n",
    "        self.clf = lgb.train(self.params, dtrain, num_iterations)\n",
    " \n",
    "    def predict(self, X):\n",
    "#        dtest = lgb.Dataset(X)\n",
    "        return self.clf.predict(X)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict(X)\n",
    "        return r2_score(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_iterations' in params:\n",
    "            self.num_iterations = params.pop('num_iterations')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LgbReg(\n",
    "                learning_rate = 0.001,\n",
    "                boosting_type = 'gbdt',\n",
    "                metric = 'l2',\n",
    "                sub_feature = 0.9,\n",
    "                bagging_fraction = 0.9,\n",
    "                num_leaves = 32,\n",
    "                min_data = 100,\n",
    "                min_hessian = 0.05)\n",
    "\n",
    "parameters = {\n",
    "        'num_iterations': [700, 750],\n",
    "        'learning_rate': [0.005],\n",
    "        'num_leaves': [8, 9],\n",
    "        'bagging_fraction': [0.6, 0.65],\n",
    "        'sub_feature': [0.7, 0.8],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 8, 'sub_feature': 0.7, 'min_hessian': 0.05, 'verbose': 1, 'metric': 'l2', 'min_data': 100, 'max_bin': 255, 'objective': 'regression', 'categorical_column': [], 'bagging_fraction': 0.6, 'learning_rate': 0.005, 'boosting_type': 'gbdt'}\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "grid = GridSearchCV(model, parameters, scoring=r2_scorer, cv=5)\n",
    "grid_obj = grid.fit(stack, y)\n",
    "\n",
    "grid_best = grid_obj.best_estimator_\n",
    "print grid_best.params\n",
    "print grid_best.num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/Software/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594543453053\n",
      "0.643196018301\n",
      "0.586328557554\n",
      "0.604681135843\n",
      "0.543354241066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 44)\n",
    "\n",
    "train_pred = [0 for i in range(stack.shape[0])]\n",
    "test_pred = [0 for i in range(test.shape[0])]\n",
    "\n",
    "for train_index, test_index in skf.split(train, y):\n",
    "    x0, x1 = stack.iloc[train_index], stack.iloc[test_index]\n",
    "    y0, y1 = y.iloc[train_index], y.iloc[test_index] \n",
    "    grid_best.fit(x0, y0)                \n",
    "    \n",
    "    pred = grid_best.predict(x1)\n",
    "    print r2_score(y1, pred)\n",
    "#    for ii, idx in enumerate(test_index):\n",
    "#        train_pred[idx] = pred[ii]\n",
    "    \n",
    "    pred_test = grid_best.predict(test)\n",
    "    for ii, val in enumerate(pred_test):\n",
    "        test_pred[ii] += val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions from CV and save results\n",
    "y_pred = map(lambda x: x/5.0, test_pred)\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
    "output.to_csv('sub_stack_lgb_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions and save results\n",
    "grid_best.fit(stack, y)\n",
    "y_pred = grid_best.predict(test)\n",
    "\n",
    "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
    "output.to_csv('sub_stack_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
